{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tf.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Churn_Modelling.csv')\n","X = dataset.iloc[:, 3:-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","X[:, 2] = le.fit_transform(X[:, 2])\n","print(X)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')      # One hot encoding shifts the variable converted to the first column\n","X = np.array(ct.fit_transform(X))                                                                      # Hence, the 1.0 0.0 0.0 come before credit score column\n","print(X)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)                       # ALWAYS apply feature scaling to all columns in ANN's irrespective of values of the column"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann = tf.keras.models.Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # If we had a non binary output var, we would need that many units and we would one hot encode them"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"markdown","metadata":{},"source":["Whenever we have binary outcomes(Yes/No), we use loss = 'binary_crossentropy'\n","But if we had many different outputs possible, we would use loss='categorical_crossentropy'\n","Also, in that case we would have to use: model.add(tf.keras.layers.Dense(units=3, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"]},{"cell_type":"markdown","metadata":{},"source":["Predicting the result of a single observation:\n","\n","Using the ANN model to predict if the customer with the following informations will leave the bank:\n","\n","Geography: France\n","Credit Score: 600\n","Gender: Male\n","Age: 40 years old\n","Tenure: 3 years\n","Balance: $ 60000\n","Number of Products: 2\n","Does this customer have a credit card? Yes\n","Is this customer an Active Member: Yes\n","Estimated Salary: $ 50000\n","So, should we say goodbye to that customer?"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 23ms/step\n","False\n","Customer is likely to stay in this bank\n"]}],"source":["prediction = ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]))\n","temp = prediction[0][0]\n","print(temp > 0.5) \n","# Predict method always needs 2D array, hence the [[]]\n","# Don't enter France here, we have to enter the one hot encoded value\n","# We have to apply predict function to sc.transform as all values were feature scaled initially\n","# Probability > 0.5 means prediction = Yes in this case, adjust this acc to need\n","if(temp>0.5):\n","    print(\"Customer is likely to leave this bank\")\n","else:\n","    print(\"Customer is likely to stay in this bank\")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 22ms/step\n","The probability that this customer will leave the bank is: 3.13 %\n"]}],"source":["prediction = ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]))\n","probability = prediction[0][0] * 100\n","rounded_probability = round(probability, 2)\n","print(\"The probability that this customer will leave the bank is:\", rounded_probability, \"%\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":2}
